{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fejes99/PPPO-projekat/blob/main/PPPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Univerzitet u Novom Sadu**\n",
        "\n",
        "**Fakultet tehničkih nauka**\n",
        "\n",
        "**Departman za industrijsko inženjerstvo i menadžment**\n",
        "\n",
        "**Inženjerstvo informacionih sistema**\n",
        "\n",
        "**Predmet**: Principi prezentacije i prepoznavanja oblika\n",
        "\n",
        "**Tema**: Segmentacija\n",
        "\n",
        "**Student**: David Feješ IT-70/2017\n",
        "\n",
        "\n",
        "# UVOD\n",
        "\n",
        "Segmentacija predstavlja ključni aspekt analize slika. Ovaj rad se bavi segmentacijom podataka primenjujući UNet arhitekturu na skupu podataka koji se bavi detekcijom soli u seizmičkim istraživanjima. Segmentacija je tehnika izdvajanja i analize regiona od interesa na slikama.\n",
        "\n",
        "\n",
        "# SEGMENTACIJA\n",
        "\n",
        "U ovom radu primenjena je UNet arhitektura za segmentaciju slika. UNet je duboka neuronska mreža i ima sposobnost preciznog izdvajanja regiona. Ova arhitektura se sastoji iz konvolucionih slojeva za ekstrakciju karakteristika koji služe za izdvajanje karakteristika slika, kao i up-scaling slojeva koji omogućavaju generisanje segmentacionih mapa.\n",
        "\n",
        "# Metrike za evaluaciju\n",
        "\n",
        "Za evaluaciju razultata koriste se različite tehnike. Precision, recall i F1-Score su klasične metrike koje mere tačnost segmentacije u odnosu na tačno izdvojene regione sa solju. Precision se odnosi na broj pravilno identifikovanih piksela sa solju u odnosu na ukupan broj identifikovanih piksela. Recall meri koliko tačnih piksela sa solju je prepoznato u odnosu na ukupan broj piksela sa solju. F1-Score kombinuje precision i recall kako bi dao celokupnu ocenu tačnosti segmentacije.\n",
        "\n",
        "# Zaključak\n",
        "\n",
        " Segmentacija podataka ima široku primenu u mnogim oblastima, a ovaj rad se specifično fokusira na problem detekcije soli na slikama iz seizmičkih istraživanja.\n",
        "\n",
        "Ovo istraživanje omogućava bolje razumevanje tehnikа segmentacije slika i primene dubokih neuronskih mreža u analizi seizmičkih podataka. Takođe, naglašava važnost precizne segmentacije u detekciji soli, što može biti od suštinskog značaja u seizmičkim istraživanjima i drugim oblastima gde je detekcija regiona od interesa od velikog značaja.\n"
      ],
      "metadata": {
        "id": "GEJL3wByZAoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "XjLUk2x4vMi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importovanje neophodnih biblioteka koje će biti potrebne za dalju izradu projekta."
      ],
      "metadata": {
        "id": "n_dmcNefAq8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRjmC0Q7WRqk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, MaxPooling2D, GlobalMaxPool2D, Conv2D, Conv2DTranspose, concatenate, add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Povezivanje Google Drive-a."
      ],
      "metadata": {
        "id": "5FhGUwC5BH0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gc7oZGUHaXwY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metoda load_image koristi se za učitavanje i obradu fotografije. Ulazni parametar je putanja slike. Učitana slika se konvertuje u crno-belu fotografiju i biće promenjena veličina slike na 128x128 piksela."
      ],
      "metadata": {
        "id": "kJL3enPlBTZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAUBv1vkWVxF"
      },
      "outputs": [],
      "source": [
        "def load_image(img_path, show=False):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, (128,128))\n",
        "    img_tensor = img_to_array(img)\n",
        "\n",
        "    return img_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Učitavaju se slike i maske, normalizuju i skladište u liste."
      ],
      "metadata": {
        "id": "DBz-tmPDDLGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOugDXbqWXGw"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "def get_image(path):\n",
        "    data =[]\n",
        "    for subdir, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            path = os.path.join(subdir, f)\n",
        "            img = load_image(path)\n",
        "            img = img/255.0\n",
        "            data.append(img)\n",
        "    return data\n",
        "\n",
        "\n",
        "x = get_image(r'/content/gdrive/My Drive/data/train/images')\n",
        "y = get_image(r'/content/gdrive/My Drive/data/train/masks')\n",
        "\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pWaQioXsY_fK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "U ovom bloku se vrši podela slika i maski na podatke za obuku i podatke za validaciju u odnosu 80% za obuku i 20% za validaciju."
      ],
      "metadata": {
        "id": "6dLiNwulEMuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv5ZVXNGaDm2"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dK-ayliahd8"
      },
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vizuelizacija nasumično odabrane slike i njene maske."
      ],
      "metadata": {
        "id": "5Ro7EwNzE4Hq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FJmvFawakKY"
      },
      "outputs": [],
      "source": [
        "ix = random.randint(0, len(X_train))\n",
        "has_mask = y_train[ix].max() > 0\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
        "\n",
        "ax1.imshow(X_train[ix, ..., 0], cmap = 'seismic', interpolation = 'bilinear')\n",
        "if has_mask:\n",
        "    ax1.contour(y_train[ix].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])\n",
        "ax1.set_title('Seismic')\n",
        "\n",
        "ax2.imshow(y_train[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\n",
        "ax2.set_title('Salt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teQ-d4pDaqyh"
      },
      "outputs": [],
      "source": [
        "def UNet(input_img):\n",
        "    # Prvi sloj\n",
        "    c1 = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(input_img)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = Activation('relu')(c1)\n",
        "\n",
        "    c1 = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c1)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = Activation('relu')(c1)\n",
        "\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(0.1)(p1)\n",
        "\n",
        "    # Drugi sloj\n",
        "    c2 = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = Activation('relu')(c2)\n",
        "\n",
        "    c2 = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c2)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = Activation('relu')(c2)\n",
        "\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(0.1)(p2)\n",
        "\n",
        "    # Treći sloj\n",
        "    c3 = Conv2D(128, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = Activation('relu')(c3)\n",
        "\n",
        "    c3 = Conv2D(128, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = Activation('relu')(c3)\n",
        "\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(0.2)(p3)\n",
        "\n",
        "    # Četvrti sloj\n",
        "    c4 = Conv2D(256, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = Activation('relu')(c4)\n",
        "\n",
        "    c4 = Conv2D(256, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = Activation('relu')(c4)\n",
        "\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "    p4 = Dropout(0.2)(p4)\n",
        "\n",
        "    # Srednji sloj\n",
        "    c5 = Conv2D(512, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = Activation('relu')(c5)\n",
        "\n",
        "    c5 = Conv2D(512, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = Activation('relu')(c5)\n",
        "\n",
        "    # Transponovani konvolucioni slojevi za dekodiranje\n",
        "    u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(0.2)(u6)\n",
        "\n",
        "    c6 = Conv2D(256, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Activation('relu')(c6)\n",
        "\n",
        "    c6 = Conv2D(256, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Activation('relu')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(0.2)(u7)\n",
        "\n",
        "    c7 = Conv2D(128, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Activation('relu')(c7)\n",
        "\n",
        "    c7 = Conv2D(128, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Activation('relu')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(0.1)(u8)\n",
        "\n",
        "    c8 = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Activation('relu')(c8)\n",
        "\n",
        "    c8 = Conv2D(64, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Activation('relu')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(0.1)(u9)\n",
        "\n",
        "    c9 = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Activation('relu')(c9)\n",
        "\n",
        "    c9 = Conv2D(32, kernel_size=(3, 3), kernel_initializer='he_normal', padding='same')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Activation('relu')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(input_img, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompajliranje UNet modela sa Adam optimizatorom i binarnim unakrsnim entropijskim gubitkom. Nakon toga model se sumira i može se koristiti za segmentaciju slika."
      ],
      "metadata": {
        "id": "x01Y_To_EUJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shijrLDeau35"
      },
      "outputs": [],
      "source": [
        "input_img = Input((128, 128, 1), name='img')\n",
        "model = UNet(input_img)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisanje Callback funkcija:\n",
        "\n",
        "\n",
        "1.   EarlyStopping - prati performanse modela tokom treninga i prekida trening ako se gubitak na validacionom skupu ne poboljšava u narednih 10 epoha. Pomaže sprečavanju overfitting-a i trening se završava kada model prestane da se poboljšava.\n",
        "2.   ReduceLROnPlateau - smanjuje stopu učenja ako se rezultat na validacionom skupu ne poboljša u narednih 5 epoha.\n",
        "3.   ModelCheckpoint - čuva najbolji model\n",
        "\n"
      ],
      "metadata": {
        "id": "scHzx362GHOo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SekETzoYaybj"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('/content/gdrive/My Drive/best_model_during_training.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trening samog modela."
      ],
      "metadata": {
        "id": "tpm0RZ8PIU_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFgQzecva1Jc"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=callbacks,\\\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/My Drive/final_model_after_training.h5')"
      ],
      "metadata": {
        "id": "YZNYl59ExBXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U ovom bloku model vrši predikciju na skupu za obuku i skupu za validaciju."
      ],
      "metadata": {
        "id": "pwZK5MTwKIBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_train = model.predict(X_train, verbose=1)\n",
        "preds_val = model.predict(X_valid, verbose=1)"
      ],
      "metadata": {
        "id": "r8Gx023712N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "ahsdartp3yTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    # Threshold the ground truth masks to binary format\n",
        "    y_true_bin = (y_true > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Threshold the predictions to binary format\n",
        "    y_pred_bin = (y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    confusion = confusion_matrix(y_true_bin.ravel(), y_pred_bin.ravel())\n",
        "\n",
        "    # Calculate precision, recall, and F1-Score\n",
        "    precision = precision_score(y_true_bin.ravel(), y_pred_bin.ravel())\n",
        "    recall = recall_score(y_true_bin.ravel(), y_pred_bin.ravel())\n",
        "    f1 = f1_score(y_true_bin.ravel(), y_pred_bin.ravel())\n",
        "\n",
        "    # Convert precision to percentage\n",
        "    precision_percent = precision * 100\n",
        "\n",
        "    return confusion, precision, recall, f1, precision_percent\n",
        "\n",
        "# Calculate metrics for training set\n",
        "confusion_train, precision_train, recall_train, f1_train, precision_train_percent = calculate_metrics(y_train, preds_train)\n",
        "\n",
        "# Calculate metrics for validation set\n",
        "confusion_val, precision_val, recall_val, f1_val, precision_val_percent = calculate_metrics(y_valid, preds_val)\n",
        "\n",
        "# Print and visualize the metrics\n",
        "print(\"Training Precision:\", precision_train)\n",
        "print(\"Training Precision Percentage:\", precision_train_percent, \"%\")\n",
        "print(\"Training Recall:\", recall_train)\n",
        "print(\"Training F1-Score:\", f1_train)\n",
        "\n",
        "print(\"Validation Precision:\", precision_val)\n",
        "print(\"Validation Precision Percentage:\", precision_val_percent, \"%\")\n",
        "print(\"Validation Recall:\", recall_val)\n",
        "print(\"Validation F1-Score:\", f1_val)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].matshow(confusion_train, cmap=plt.cm.Blues, alpha=0.7)\n",
        "axes[0].set_title(\"Training Confusion Matrix\")\n",
        "axes[1].matshow(confusion_val, cmap=plt.cm.Blues, alpha=0.7)\n",
        "axes[1].set_title(\"Validation Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K17O_2WP772k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(X, y, preds, binary_preds):\n",
        "    ix = random.randint(0, len(X))\n",
        "\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
        "    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n",
        "    if has_mask:\n",
        "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[0].set_title('Seismic')\n",
        "\n",
        "    ax[1].imshow(y[ix].squeeze())\n",
        "    ax[1].set_title('Salt')\n",
        "\n",
        "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[2].set_title('Salt Predicted')\n",
        "\n",
        "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[3].set_title('Salt Predicted binary');"
      ],
      "metadata": {
        "id": "UegOA6Gd1_ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(X_train, y_train, preds_train, preds_train_t)"
      ],
      "metadata": {
        "id": "fGF1W_i72CKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}